{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "np.random.seed(12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current2firing_time(x, tau=20, thr=0.2, tmax=1.0, epsilon=1e-7):\n",
    "    \"\"\" Computes first firing time latency for a current input x assuming the charge time of a current based LIF neuron.\n",
    "\n",
    "    Args:\n",
    "    x -- The \"current\" values\n",
    "\n",
    "    Keyword args:\n",
    "    tau -- The membrane time constant of the LIF neuron to be charged\n",
    "    thr -- The firing threshold value\n",
    "    tmax -- The maximum time returned\n",
    "    epsilon -- A generic (small) epsilon > 0\n",
    "\n",
    "    Returns:\n",
    "    Time to first spike for each \"current\" x\n",
    "    \"\"\"\n",
    "    idx = x < thr\n",
    "    x = np.clip(x, thr + epsilon, 1e9)\n",
    "    T = tau * np.log(x / (x - thr))\n",
    "    T[idx] = tmax\n",
    "    return T\n",
    "\n",
    "\n",
    "def sparse_data_generator(X, y, batch_size, nb_steps, nb_units, shuffle=True):\n",
    "    \"\"\" This generator takes datasets in analog format and generates spiking network input as sparse tensors.\n",
    "\n",
    "    Args:\n",
    "        X: The data ( sample x event x 2 ) the last dim holds (time,neuron) tuples\n",
    "        y: The labels\n",
    "    \"\"\"\n",
    "\n",
    "    labels_ = np.array(y, dtype=np.int)\n",
    "    number_of_batches = len(X) // batch_size\n",
    "    sample_index = np.arange(len(X))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    tau_eff = 20e-3 / time_step\n",
    "    firing_times = np.array(current2firing_time(X, tau=tau_eff, tmax=nb_steps), dtype=np.int)\n",
    "    unit_numbers = np.arange(nb_units)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "    while counter < number_of_batches:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "\n",
    "        coo = [[] for i in range(3)]\n",
    "        for bc, idx in enumerate(batch_index):\n",
    "            c = firing_times[idx] < nb_steps\n",
    "            times, units = firing_times[idx][c], unit_numbers[c]\n",
    "\n",
    "            batch = [bc for _ in range(len(times))]\n",
    "            coo[0].extend(batch)\n",
    "            coo[1].extend(times)\n",
    "            coo[2].extend(units)\n",
    "\n",
    "        i = torch.LongTensor(coo).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "\n",
    "        X_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size, nb_steps, nb_units])).to(device)\n",
    "        y_batch = torch.tensor(labels_[batch_index], device=device)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "def get_mini_batch(x_data, y_data, shuffle=False):\n",
    "    for ret in sparse_data_generator(x_data, y_data, batch_size, nb_steps, nb_inputs, shuffle=shuffle):\n",
    "        return ret\n",
    "\n",
    "\n",
    "def spike_fn(x):\n",
    "    out = torch.zeros_like(x, requires_grad=False)\n",
    "    out[x > 0] = 1.0\n",
    "    return out\n",
    "\n",
    "\n",
    "def plot_voltage_traces(mem, spk=None, dim=(3, 5), spike_height=5):\n",
    "    gs = GridSpec(*dim)\n",
    "    if spk is not None:\n",
    "        dat = (mem + spike_height * spk).detach().cpu().numpy()\n",
    "    else:\n",
    "        dat = mem.detach().cpu().numpy()\n",
    "    for i in range(np.prod(dim)):\n",
    "        if i == 0:\n",
    "            a0 = ax = plt.subplot(gs[i])\n",
    "        else:\n",
    "            ax = plt.subplot(gs[i], sharey=a0)\n",
    "        ax.plot(dat[i])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def plot_single_traces(trace, spk=None, spike_height=5, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    if spk is not None:\n",
    "        dat = (trace + spike_height * spk).detach().cpu().numpy()\n",
    "    else:\n",
    "        dat = trace.detach().cpu().numpy()\n",
    "    ax.plot(dat[0])\n",
    "\n",
    "\n",
    "def run_snn(inputs):\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    syn = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = [mem]\n",
    "    spk_rec = [mem]\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(nb_steps):\n",
    "        mthr = mem - 1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = torch.zeros_like(mem, requires_grad=False)\n",
    "        c = (mthr > 0)\n",
    "        rst[c] = torch.ones_like(mem)[c]\n",
    "\n",
    "        new_syn = alpha * syn + h1[:, t]\n",
    "        new_mem = beta * mem + syn - rst\n",
    "\n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec, dim=1)\n",
    "    spk_rec = torch.stack(spk_rec, dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2 = torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    syn = torch.zeros((batch_size, nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size, nb_outputs), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size, nb_outputs), device=device, dtype=dtype)\n",
    "    spk_o_rec = [out]\n",
    "    mem_o_rec = [mem]\n",
    "    for t in range(nb_steps):\n",
    "        mthr = mem - 1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = torch.zeros_like(mem, requires_grad=False)\n",
    "        c = (mthr > 0)\n",
    "        rst[c] = torch.ones_like(mem)[c]\n",
    "\n",
    "        new_syn = alpha * syn + h2[:, t]\n",
    "        new_mem = beta * mem + syn - rst\n",
    "\n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "        spk_o_rec.append(out)\n",
    "        mem_o_rec.append(mem)\n",
    "\n",
    "    spk_o_rec = torch.stack(spk_o_rec, dim=1)\n",
    "    mem_o_rec = torch.stack(mem_o_rec, dim=1)\n",
    "    out_recs = [mem_o_rec, spk_o_rec]\n",
    "    other_recs = [mem_rec, spk_rec]\n",
    "    return out_recs, other_recs\n",
    "\n",
    "\n",
    "def get_eltr(hidden_rec, x_data, out_rec):\n",
    "    # HIDDEN LAYER\n",
    "    presyn = torch.zeros((batch_size, nb_inputs), device=device, dtype=dtype)\n",
    "    eltr = torch.zeros((batch_size, nb_hidden, nb_inputs), device=device, dtype=dtype)\n",
    "    surr = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    surrgradscale = 5\n",
    "    surr_rec = [surr]\n",
    "    eltr_rec = [eltr]\n",
    "    mem_rec = hidden_rec[0]\n",
    "    for t in range(nb_steps):\n",
    "        c = (mem_rec[:, t] - 1.0 > 0)\n",
    "        surr = 1 / (surrgradscale * torch.abs(mem_rec[:, t] - 1.0) + 1.0) ** 2\n",
    "        surr = torch.clamp(surr, min=0.0, max=1.0)\n",
    "\n",
    "        new_presyn = alpha * presyn + x_data[:, t]\n",
    "        new_eltr = beta * eltr + torch.einsum(\"ab,ac->abc\", (surr, new_presyn))\n",
    "\n",
    "        presyn = new_presyn\n",
    "        eltr = new_eltr\n",
    "\n",
    "        eltr_rec.append(eltr)\n",
    "        surr_rec.append(surr)\n",
    "\n",
    "    eltr_rec = torch.stack(eltr_rec, dim=1)\n",
    "    surr_rec = torch.stack(surr_rec, dim=1)\n",
    "\n",
    "    # READOUT LAYER\n",
    "    presyn_o = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    eltr_o = torch.zeros((batch_size, nb_outputs, nb_hidden), device=device, dtype=dtype)\n",
    "    surr_o = torch.zeros((batch_size, nb_outputs), device=device, dtype=dtype)\n",
    "\n",
    "    surr_o_rec = [surr_o]\n",
    "    eltr_o_rec = [eltr_o]\n",
    "    mem_rec = out_rec[0]\n",
    "    spikes = hidden_rec[1]\n",
    "    for t in range(nb_steps):\n",
    "        c = (mem_rec[:, t] - 1.0 > 0)\n",
    "        surr_o = 1 / (surrgradscale * torch.abs(mem_rec[:, t] - 1.0) + 1.0) ** 2\n",
    "        surr_o = torch.clamp(surr_o, min=0.0, max=1.0)\n",
    "\n",
    "        new_presyn_o = alpha * presyn_o + spikes[:, t]\n",
    "        new_eltr_o = beta * eltr_o + torch.einsum(\"ab,ac->abc\", (surr_o, new_presyn_o))\n",
    "\n",
    "        presyn_o = new_presyn_o\n",
    "        eltr_o = new_eltr_o\n",
    "\n",
    "        eltr_o_rec.append(eltr_o)\n",
    "        surr_o_rec.append(surr_o)\n",
    "\n",
    "    eltr_o_rec = torch.stack(eltr_o_rec, dim=1)\n",
    "    surr_o_rec = torch.stack(surr_o_rec, dim=1)\n",
    "\n",
    "    return eltr_rec, eltr_o_rec, surr_rec, surr_o_rec\n",
    "\n",
    "\n",
    "def error(spk_rec, labels, target_window=(1, 120), dflt_spk=35):\n",
    "    start, end = target_window\n",
    "\n",
    "    # test if spikes are where they shouldnt be\n",
    "    mask = torch.ones_like(spk_rec, dtype=bool, requires_grad=False)  # (n_batches, time, n_outputs)\n",
    "    for i, l in enumerate(labels):\n",
    "        mask[i, start:end, l] = False\n",
    "\n",
    "    outside_spk = -spk_rec * mask\n",
    "\n",
    "    # there is no spike but there should be\n",
    "    inside_spk = torch.zeros_like(spk_rec, requires_grad=False)\n",
    "    inside_mask = torch.zeros(batch_size, dtype=bool, requires_grad=False)\n",
    "\n",
    "    for o in range(nb_outputs):\n",
    "        inside_mask[labels == o] = torch.sum(spk_rec[labels == o, start:end, o], dim=1, dtype=bool)\n",
    "\n",
    "    inside_spk[inside_mask, dflt_spk, labels[inside_mask]] = 1\n",
    "\n",
    "    err_spk = inside_spk + outside_spk\n",
    "\n",
    "    # convolution\n",
    "    err = torch.zeros_like(spk_rec[:, 0, :], requires_grad=False)\n",
    "    err_rec = [err]\n",
    "    for t in range(nb_steps):\n",
    "        new_err = eps * err + err_spk[:, t]\n",
    "        err = new_err\n",
    "        err_rec.append(err)\n",
    "\n",
    "    err_rec = torch.stack(err_rec, dim=1)\n",
    "    return err_rec\n",
    "\n",
    "def classification_accuracy(spk_rec, labels, target_window=(1, 80)):\n",
    "    start, end = target_window\n",
    "\n",
    "    # there is no spike but there should be\n",
    "    inside_mask = torch.zeros(batch_size, dtype=bool, requires_grad=False)\n",
    "    outside_mask = torch.zeros(batch_size, dtype=bool, requires_grad=False)\n",
    "    outside = torch.ones(nb_steps+1, dtype=bool, requires_grad=False)  # (n_batches, time, n_outputs)\n",
    "    outside[start:end] = False\n",
    "\n",
    "    for o in range(nb_outputs):\n",
    "        inside_mask[labels == o] = torch.sum(spk_rec[labels == o, start:end, o], dim=1, dtype=bool)\n",
    "        outside_mask[labels == o] = torch.sum(spk_rec[labels == o, :start, o], dim=1, dtype=bool)\n",
    "        outside_mask[labels == o] += torch.sum(spk_rec[labels == o, end:, o], dim=1, dtype=bool)\n",
    "\n",
    "    accuracy = inside_mask & ~outside_mask\n",
    "    acc = np.mean(accuracy.detach().cpu().numpy())\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_inputs = 28 * 28\n",
    "nb_hidden = 100\n",
    "nb_outputs = 10\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps = 100\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to run on GPU\n",
    "# device = torch.device(\"cuda:0\")\n",
    "\n",
    "root = os.path.expanduser(\"~/data/datasets/torch/fashion-mnist\")\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root, train=True, transform=None, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root, train=False, transform=None, target_transform=None, download=True)\n",
    "\n",
    "# Standardize data\n",
    "# x_train = torch.tensor(train_dataset.train_data, device=device, dtype=dtype)\n",
    "x_train = np.array(train_dataset.data, dtype=np.float)\n",
    "x_train = x_train.reshape(x_train.shape[0], -1) / 255\n",
    "# x_test = torch.tensor(test_dataset.test_data, device=device, dtype=dtype)\n",
    "x_test = np.array(test_dataset.data, dtype=np.float)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) / 255\n",
    "\n",
    "# y_train = torch.tensor(train_dataset.train_labels, device=device, dtype=dtype)\n",
    "# y_test  = torch.tensor(test_dataset.test_labels, device=device, dtype=dtype)\n",
    "y_train = np.array(train_dataset.targets, dtype=np.int)\n",
    "y_test = np.array(test_dataset.targets, dtype=np.int)\n",
    "\n",
    "# time constants\n",
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "tau_eps = 10e-3\n",
    "alpha = float(np.exp(-time_step / tau_syn))\n",
    "eps = float(np.exp(-time_step / tau_eps))\n",
    "beta = float(np.exp(-time_step / tau_mem))\n",
    "\n",
    "# init weights for SNN\n",
    "weight_scale = 7 * (1.0 - beta)  # this should give us some spikes to begin with\n",
    "\n",
    "w1 = torch.empty((nb_inputs, nb_hidden), device=device, dtype=dtype, requires_grad=False)\n",
    "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale / np.sqrt(nb_inputs))\n",
    "\n",
    "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=False)\n",
    "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale / np.sqrt(nb_hidden))\n",
    "\n",
    "params = [w1, w2]\n",
    "optimizer = torch.optim.SGD(params, lr=8e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "tensor(871.8351)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-36c75ada3ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# grad and error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0merr_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_rec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mgrad_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"abdc, abd->acd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meltr_o_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f0b76d80cc67>\u001b[0m in \u001b[0;36merror\u001b[0;34m(spk_rec, labels, target_window, dflt_spk)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0minside_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk_rec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0minside_spk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minside_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdflt_spk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minside_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start training\n",
    "gc.collect()\n",
    "print(\"start training\")\n",
    "nb_epochs = 20\n",
    "subset = 128\n",
    "totalloss = []\n",
    "totalacc = []\n",
    "for e in range(nb_epochs):\n",
    "    loss = []\n",
    "    acc = []\n",
    "    for x_local, y_local in sparse_data_generator(x_train[:subset], y_train[:subset], batch_size, nb_steps, nb_inputs):\n",
    "        out_rec, hidden_rec = run_snn(x_local.to_dense())\n",
    "\n",
    "        # eltr\n",
    "        eltr_rec, eltr_o_rec, surr_rec, surr_o_rec = get_eltr(hidden_rec, x_local.to_dense(), out_rec)\n",
    "\n",
    "        # grad and error\n",
    "        err_o = error(out_rec[1], y_local)\n",
    "        grad_o = torch.mean(torch.einsum(\"abdc, abd->acd\", (eltr_o_rec, err_o)), dim=0)\n",
    "\n",
    "        err = torch.einsum(\"abd,dc->abc\", (err_o, w2.T))\n",
    "        grad = torch.mean(torch.einsum(\"abdc, abd->acd\", (eltr_rec, err)), dim=0)\n",
    "\n",
    "        # acc (before update!)\n",
    "        acc.append(classification_accuracy(out_rec[1], y_local))\n",
    "        # calculate gradients\n",
    "        optimizer.zero_grad()\n",
    "        w2.grad = -grad_o\n",
    "        w1.grad = -grad\n",
    "        optimizer.step()\n",
    "        loss.append(torch.sum(torch.abs(err_o)))\n",
    "        print(loss[-1])\n",
    "    gc.collect()\n",
    "    totalloss.append(np.mean(loss))\n",
    "    totalacc.append(np.mean(acc))\n",
    "    print(\"%s/40: av. loss = %s, acc = %s\" % (e, totalloss[-1], totalacc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.375]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_accuracy(out_rec[1], y_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, sharex=True, figsize=(3,3))\n",
    "axes[0].plot(totalloss)\n",
    "axes[1].plot(totalacc)\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[1].set_ylabel(\"Training Accuracy\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "sns.despine()\n",
    "plt.savefig(\"loss.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
